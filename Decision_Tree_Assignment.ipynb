{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Theoretical"
      ],
      "metadata": {
        "id": "RR-cHZEcPYRU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6946429e"
      },
      "source": [
        "Ques -1. What is a Decision Tree, and how does it work?\n",
        "\n",
        "--> A Decision Tree is a supervised machine learning algorithm that is used for both classification and regression tasks. It's a tree-like structure where each internal node represents a test on an attribute, each branch represents an outcome of the test, and each leaf node represents a class label (in classification) or a predicted value (in regression).\n",
        "\n",
        "How it works:\n",
        "\n",
        "1.  **Splitting**: The algorithm starts with a single node representing the entire dataset (the root node). It then recursively splits the data into smaller subsets based on the most \"informative\" attribute at each node. The goal is to create splits that result in subsets that are as pure as possible with respect to the target variable (i.e., subsets where most instances belong to the same class or have similar predicted values).\n",
        "2.  **Attribute Selection**: The choice of which attribute to split on at each node is determined by measures like Gini impurity or entropy (for classification), or variance reduction (for regression). These measures quantify how well a split separates the data based on the target variable.\n",
        "3.  **Stopping Criteria**: The splitting process continues until a stopping criterion is met. This could be:\n",
        "    *   All instances in a node belong to the same class.\n",
        "    *   There are no more attributes to split on.\n",
        "    *   A predefined maximum depth of the tree is reached.\n",
        "    *   The number of instances in a node falls below a minimum threshold.\n",
        "4.  **Prediction**: Once the tree is built, predictions are made by traversing the tree from the root node down to a leaf node. For a new instance, you follow the branches that correspond to the instance's attribute values until you reach a leaf node. The prediction is then based on the value in that leaf node (either the majority class in classification or the average value in regression).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8f204f6"
      },
      "source": [
        "Ques -2. What are impurity measures in Decision Trees?\n",
        "\n",
        "--> Impurity measures in Decision Trees are metrics used to evaluate the homogeneity or heterogeneity of the target variable within a subset of data. The goal of the decision tree algorithm is to create splits that reduce the impurity of the resulting subsets as much as possible. Lower impurity means the instances in that subset are more similar with respect to the target variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afffdbcb"
      },
      "source": [
        "Ques -3. What is the mathematical formula for Gini Impurity?\n",
        "\n",
        "--> The mathematical formula for Gini Impurity for a node with \\(k\\) classes is:\n",
        "\n",
        "$$ Gini = 1 - \\sum_{i=1}^{k} (p_i)^2 $$\n",
        "\n",
        "Where:\n",
        "- \\(Gini\\) is the Gini Impurity of the node.\n",
        "- \\(k\\) is the number of classes in the target variable.\n",
        "- \\(p_i\\) is the proportion of instances belonging to class \\(i\\) in the node.\n",
        "\n",
        "In simpler terms, the formula calculates the sum of the squared probabilities of each class present in the node and subtracts this sum from 1.\n",
        "\n",
        "*   If a node is perfectly pure (all instances belong to the same class), one of the \\(p_i\\) values will be 1, and all others will be 0. In this case, \\(1 - (1^2 + 0^2 + ... + 0^2) = 1 - 1 = 0\\). The Gini impurity is 0.\n",
        "*   If a node is impure (instances belong to multiple classes), the sum of the squared probabilities will be less than 1, resulting in a Gini impurity greater than 0. The maximum Gini impurity occurs when the classes are equally distributed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ef784e"
      },
      "source": [
        "Ques -4. What is the mathematical formula for Entropy?\n",
        "\n",
        "--> The mathematical formula for Entropy for a node with \\(k\\) classes is:\n",
        "\n",
        "$$ Entropy = -\\sum_{i=1}^{k} p_i \\log_2(p_i) $$\n",
        "\n",
        "Where:\n",
        "- \\(Entropy\\) is the Entropy of the node.\n",
        "- \\(k\\) is the number of classes in the target variable.\n",
        "- \\(p_i\\) is the proportion of instances belonging to class \\(i\\) in the node.\n",
        "\n",
        "In simpler terms, the formula calculates the sum of the product of the probability of each class and the base-2 logarithm of that probability, and then negates the result.\n",
        "\n",
        "*   If a node is perfectly pure (all instances belong to the same class), one of the \\(p_i\\) values will be 1, and all others will be 0. The logarithm of 1 is 0, so the entropy will be 0.\n",
        "*   If a node is impure (instances belong to multiple classes), the entropy will be greater than 0. The maximum entropy occurs when the classes are equally distributed, indicating the highest level of uncertainty."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab040103"
      },
      "source": [
        "Ques -5. What is Information Gain, and how is it used in Decision Trees?\n",
        "\n",
        "--> **Information Gain** is a concept used in Decision Trees (specifically in algorithms like ID3 and C4.5) to determine the best attribute to split the data on at each node. It measures the reduction in entropy or impurity achieved by splitting the data based on a particular attribute.\n",
        "\n",
        "The formula for Information Gain when splitting on attribute \\(A\\) is:\n",
        "\n",
        "$$ Information\\ Gain(S, A) = Entropy(S) - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|} Entropy(S_v) $$\n",
        "\n",
        "Where:\n",
        "- \\(Information\\ Gain(S, A)\\) is the information gain when splitting dataset \\(S\\) on attribute \\(A\\).\n",
        "- \\(Entropy(S)\\) is the entropy of the dataset \\(S\\) before the split.\n",
        "- \\(Values(A)\\) is the set of possible values for attribute \\(A\\).\n",
        "- \\(S_v\\) is the subset of \\(S\\) where attribute \\(A\\) has value \\(v\\).\n",
        "- \\(|S_v|\\) is the number of instances in the subset \\(S_v\\).\n",
        "- \\(|S|\\) is the total number of instances in the dataset \\(S\\).\n",
        "- \\(Entropy(S_v)\\) is the entropy of the subset \\(S_v\\).\n",
        "\n",
        "**How it is used in Decision Trees:**\n",
        "\n",
        "The decision tree algorithm uses Information Gain to select the attribute that provides the most information about the target variable. At each node, the algorithm calculates the Information Gain for all available attributes and chooses the attribute that results in the highest Information Gain. This attribute is then used to split the data at that node.\n",
        "\n",
        "The goal is to select splits that lead to the most \"pure\" subsets of data, where instances within each subset are more likely to belong to the same class. A higher Information Gain indicates a more effective split in reducing the uncertainty or impurity of the data.\n",
        "\n",
        "In algorithms that use Gini Impurity instead of Entropy (like CART), a similar concept called **Gini Gain** or **Gini Reduction** is used, which measures the reduction in Gini Impurity after a split. The principle is the same: select the attribute that maximizes the reduction in impurity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fefc9e47"
      },
      "source": [
        "Ques -6. What is the difference between Gini Impurity and Entropy?\n",
        "\n",
        "--> Gini Impurity and Entropy are both impurity measures used in Decision Trees to evaluate the homogeneity of a dataset with respect to the target variable. While they serve the same purpose â€“ helping the algorithm decide the best split at each node â€“ they have some key differences:\n",
        "\n",
        "1.  **Mathematical Formula**:\n",
        "    *   **Gini Impurity**: \\( Gini = 1 - \\sum_{i=1}^{k} (p_i)^2 \\)\n",
        "    *   **Entropy**: \\( Entropy = -\\sum_{i=1}^{k} p_i \\log_2(p_i) \\)\n",
        "\n",
        "2.  **Interpretation**:\n",
        "    *   **Gini Impurity**: Measures the probability of misclassifying a randomly chosen element if it were labeled according to the class distribution in the subset. A value of 0 indicates perfect purity.\n",
        "    *   **Entropy**: Measures the level of randomness or uncertainty in the subset. A value of 0 indicates perfect purity.\n",
        "\n",
        "3.  **Computational Cost**:\n",
        "    *   **Gini Impurity**: Involves squaring probabilities, which is computationally less expensive than calculating logarithms.\n",
        "    *   **Entropy**: Involves calculating logarithms, which is generally more computationally expensive than squaring.\n",
        "\n",
        "4.  **Sensitivity to Class Distribution**:\n",
        "    *   **Gini Impurity**: Tends to isolate the most frequent class in a node.\n",
        "    *   **Entropy**: Tends to create more balanced trees, where the classes are more evenly distributed in the child nodes.\n",
        "\n",
        "5.  **Range of Values**:\n",
        "    *   **Gini Impurity**: Ranges from 0 (perfect purity) to 0.5 (maximum impurity in a binary classification). The maximum value for multi-class classification is \\(1 - \\frac{1}{k}\\).\n",
        "    *   **Entropy**: Ranges from 0 (perfect purity) to 1 (maximum impurity in a binary classification). The maximum value for multi-class classification is \\(\\log_2(k)\\).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6613206d"
      },
      "source": [
        "Ques -7. What is the mathematical explanation behind Decision Trees?\n",
        "\n",
        "--> The mathematical foundation of Decision Trees lies in the concepts of **information theory** and **optimization**. The core idea is to recursively partition the data space into regions that are as \"pure\" as possible with respect to the target variable. This partitioning is guided by mathematical measures of impurity and information gain.\n",
        "\n",
        "Here's a breakdown of the key mathematical concepts:\n",
        "\n",
        "1.  **Impurity Measures (Entropy and Gini Impurity)**:\n",
        "    *   As discussed earlier, Entropy and Gini Impurity quantify the homogeneity of a set of data points.\n",
        "    *   **Mathematically**, for a set \\(S\\) with \\(k\\) classes, the impurity is calculated based on the probability distribution of the classes within that set (\\(p_i\\) for each class \\(i\\)).\n",
        "    *   The goal is to find splits that **minimize** the impurity of the resulting child nodes.\n",
        "\n",
        "2.  **Information Gain**:\n",
        "    *   Information Gain measures the reduction in entropy (or impurity) achieved by splitting the data on a particular attribute.\n",
        "    *   **Mathematically**, it's the difference between the impurity of the parent node and the weighted average of the impurities of the child nodes. The weights are proportional to the number of instances in each child node.\n",
        "    *   The decision tree algorithm aims to **maximize** Information Gain at each split, as this indicates the attribute that best separates the data according to the target variable.\n",
        "\n",
        "3.  **Splitting Criterion**:\n",
        "    *   At each internal node, the algorithm evaluates all possible splits for each available attribute.\n",
        "    *   For **categorical attributes**, the splits are based on the different values of the attribute.\n",
        "    *   For **numerical attributes**, the algorithm considers various threshold values to create binary splits (e.g., `attribute <= threshold` and `attribute > threshold`).\n",
        "    *   The mathematical criterion used to select the best split is typically the one that maximizes Information Gain (or minimizes Gini Impurity).\n",
        "\n",
        "4.  **Recursive Partitioning**:\n",
        "    *   The process of splitting the data is applied recursively to the child nodes. This creates the tree structure.\n",
        "    *   The recursion stops when a stopping criterion is met (e.g., a node is pure, maximum depth is reached, minimum number of samples per node is met). These stopping criteria are also defined mathematically.\n",
        "\n",
        "5.  **Prediction**:\n",
        "    *   For a new instance, the prediction is made by traversing the tree based on the instance's attribute values.\n",
        "    *   In **classification trees**, the prediction is the majority class in the leaf node reached. This is a simple probabilistic assignment based on the class distribution in that leaf.\n",
        "    *   In **regression trees**, the prediction is typically the average (or median) of the target variable values in the leaf node reached. This is a mathematical aggregation of the values in that region of the data space.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21109002"
      },
      "source": [
        "Ques -8. What is Pre-Pruning in Decision Trees?\n",
        "\n",
        "--> **Pre-pruning** (also known as early stopping or forward pruning) is a technique used to prevent overfitting in Decision Trees by stopping the tree building process early, before it has fully grown. Instead of building a complete tree and then pruning it back (post-pruning), pre-pruning imposes constraints during the tree construction phase to limit its complexity.\n",
        "\n",
        "The idea behind pre-pruning is to stop splitting a node when the potential gain from the split is not significant or when further splitting would likely lead to overfitting on the training data. This helps to create a simpler, more generalized tree that is less likely to perform poorly on unseen data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef1be611"
      },
      "source": [
        "Ques -9. What is Post-Pruning in Decision Trees?\n",
        "\n",
        "--> **Post-pruning** (also known as backward pruning) is a technique used to prevent overfitting in Decision Trees by building a complete tree first and then pruning back the branches that do not contribute to improving the tree's performance on unseen data. Unlike pre-pruning, which stops the tree building process early, post-pruning allows the tree to grow to its full potential and then removes unnecessary complexity.\n",
        "\n",
        "The idea behind post-pruning is to identify and remove subtrees that are likely to be the result of overfitting on the training data. These subtrees might capture noise or specific patterns in the training data that do not generalize well to new data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4f164c5"
      },
      "source": [
        "Ques -10. What is the difference between Pre-Pruning and Post-Pruning?\n",
        "\n",
        "--> The main difference between Pre-pruning and Post-pruning in Decision Trees lies in **when** the pruning occurs:\n",
        "\n",
        "1.  **Pre-Pruning (Early Stopping)**:\n",
        "    *   **When it happens**: During the tree building process.\n",
        "    *   **How it works**: It stops the growth of the tree at an earlier stage based on predefined criteria.\n",
        "    *   **Goal**: To prevent the tree from growing too complex and overfitting the training data from the beginning.\n",
        "    *   **Methods**: Involves setting parameters like maximum depth, minimum samples per split, minimum impurity decrease, etc.\n",
        "    *   **Pros**: Faster training, simpler trees, less risk of overfitting from the start.\n",
        "    *   **Cons**: Greedy approach may lead to suboptimal trees, difficult to set optimal thresholds.\n",
        "\n",
        "2.  **Post-Pruning (Backward Pruning)**:\n",
        "    *   **When it happens**: After the tree has been fully grown.\n",
        "    *   **How it works**: It trims back branches from the fully grown tree based on their impact on a validation dataset or a complexity measure.\n",
        "    *   **Goal**: To remove subtrees that are likely due to overfitting on the training data.\n",
        "    *   **Methods**: Includes techniques like Reduced Error Pruning and Cost-Complexity Pruning.\n",
        "    *   **Pros**: Potentially finds more optimal subtrees, less reliant on arbitrary thresholds.\n",
        "    *   **Cons**: More computationally expensive, requires a validation set for some methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2c2bc4e"
      },
      "source": [
        "Ques -11. What is a Decision Tree Regressor?\n",
        "\n",
        "--> A **Decision Tree Regressor** is a supervised machine learning algorithm used for **regression tasks**. Unlike a Decision Tree Classifier, which predicts a categorical class label, a Decision Tree Regressor predicts a continuous numerical value. It works by partitioning the data space into a set of rectangular regions and predicting the average (or median) target value for all instances within each region.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82d17ad2"
      },
      "source": [
        "Ques -12. What are the advantages and disadvantages of Decision Trees?\n",
        "\n",
        "--> Decision Trees are a popular and widely used machine learning algorithm due to their simplicity and interpretability. However, they also have certain limitations. Here's a breakdown of their advantages and disadvantages:\n",
        "\n",
        "**Advantages of Decision Trees:**\n",
        "\n",
        "1.  **Easy to Understand and Interpret**: Decision trees are visually intuitive and easy to follow. The tree structure can be easily understood by non-experts, making them valuable for explaining model decisions.\n",
        "2.  **Handle Both Categorical and Numerical Data**: Decision trees can work with both categorical and numerical input features without requiring extensive data preprocessing like feature scaling.\n",
        "3.  **No Assumption about Data Distribution**: Unlike some other algorithms (e.g., linear regression), decision trees do not make assumptions about the underlying data distribution.\n",
        "4.  **Captures Non-linear Relationships**: Decision trees can effectively capture non-linear relationships between features and the target variable.\n",
        "5.  **Feature Selection is Implicit**: The tree building process inherently performs a form of feature selection. Features that are more important for splitting the data appear higher up in the tree.\n",
        "6.  **Handle Missing Values**: Some implementations of decision trees can handle missing values by using various strategies, such as assigning the instance to the most frequent category or the category with the highest probability.\n",
        "7.  **Can be Used for Both Classification and Regression**: Decision trees are versatile and can be applied to both classification (predicting categorical labels) and regression (predicting continuous values) tasks.\n",
        "\n",
        "**Disadvantages of Decision Trees:**\n",
        "\n",
        "1.  **Prone to Overfitting**: Decision trees, especially deep ones, can easily overfit the training data. They can capture noise and specific patterns in the training set that do not generalize well to unseen data. Pruning techniques are essential to mitigate this.\n",
        "2.  **Instability (High Variance)**: Small variations in the training data can lead to significantly different tree structures. This instability makes them sensitive to the specific training set.\n",
        "3.  **Bias Towards Features with More Levels**: Decision trees tend to favor features with a larger number of distinct values or levels, as they can create more splits and potentially achieve higher information gain (or lower impurity) at an early stage.\n",
        "4.  **Difficulty in Handling Continuous Numerical Data (without binning)**: While they can handle numerical data, the splits are based on specific threshold values. This can sometimes lead to a staircase-like prediction function for regression tasks if not handled carefully (e.g., by combining with ensemble methods or using techniques like binning).\n",
        "5.  **Can Create Biased Trees**: If the dataset is imbalanced (one class is much more frequent than others), the decision tree might become biased towards the majority class.\n",
        "6.  **Computational Cost for Large Trees**: Building a very large decision tree can be computationally expensive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dceebe5a"
      },
      "source": [
        "Ques -13. How does a Decision Tree handle missing values?\n",
        "\n",
        "--> The way Decision Trees handle missing values can vary depending on the specific algorithm implementation. Some decision tree algorithms have built-in mechanisms to handle missing data, while others require imputation as a preprocessing step. Here are some common approaches:\n",
        "\n",
        "1.  **Ignoring Instances with Missing Values**: The simplest approach is to simply ignore instances that have missing values for a particular attribute when considering a split based on that attribute. However, this can lead to a loss of valuable data if there are many instances with missing values.\n",
        "\n",
        "2.  **Assigning to the Most Frequent Category (for categorical attributes)**: For categorical attributes with missing values, instances with missing values can be assigned to the most frequent category in the node being considered for splitting. This is a form of imputation within the tree building process.\n",
        "\n",
        "3.  **Assigning to the Category with the Highest Probability**: A more sophisticated approach for categorical attributes is to assign instances with missing values to different categories based on the probability distribution of the categories in the node. For example, if a node has 70% 'Yes' and 30% 'No' for a binary attribute, an instance with a missing value for that attribute might be sent down the 'Yes' branch with a probability of 0.7 and down the 'No' branch with a probability of 0.3.\n",
        "\n",
        "4.  **Surrogate Splits**: Some decision tree algorithms, like the one used in CART (Classification and Regression Trees), can use \"surrogate splits\" to handle missing values in numerical attributes. When considering a split on an attribute with missing values, the algorithm can identify other attributes that are highly correlated with the primary splitting attribute. If an instance has a missing value for the primary splitting attribute, the algorithm uses the surrogate attribute and its split point to decide which branch the instance should follow.\n",
        "\n",
        "5.  **Treating Missing Value as a Separate Category**: For both categorical and numerical attributes, missing values can be treated as a distinct category or value. This allows the tree to explicitly learn how missingness itself relates to the target variable.\n",
        "\n",
        "6.  **Using Imputation before Building the Tree**: If the decision tree algorithm does not have built-in missing value handling capabilities, you will need to impute the missing values before training the tree. Common imputation techniques include:\n",
        "    *   Mean, median, or mode imputation.\n",
        "    *   Using more advanced imputation methods like K-Nearest Neighbors (KNN) imputation or Multiple Imputation by Chained Equations (MICE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27a01f72"
      },
      "source": [
        "Ques -14. How does a Decision Tree handle categorical features?\n",
        "\n",
        "--> Decision Trees can handle categorical features quite naturally, without requiring extensive preprocessing like one-hot encoding (which is often necessary for linear models or support vector machines). The way a Decision Tree handles a categorical feature depends on the number of unique values (levels) the feature has.\n",
        "\n",
        "Here's a breakdown of how Decision Trees handle categorical features:\n",
        "\n",
        "1.  **Binary Categorical Features**:\n",
        "    *   For categorical features with only two unique values (e.g., \"Yes\" or \"No\", \"Male\" or \"Female\"), the decision tree will create a single split based on these two values.\n",
        "    *   The data is partitioned into two subsets: one where the feature has the first value, and another where it has the second value.\n",
        "    *   The algorithm evaluates the impurity of these two resulting subsets to determine if this split is optimal.\n",
        "\n",
        "2.  **Multi-valued Categorical Features (Nominal)**:\n",
        "    *   For categorical features with more than two unique values (e.g., \"Color\" with values \"Red\", \"Blue\", \"Green\"), the decision tree considers different ways to group these values for splitting.\n",
        "    *   **Binary Splits**: The most common approach is to create binary splits. The algorithm explores all possible ways to partition the set of unique values into two subsets. For example, if a feature has values {A, B, C}, the possible binary splits are ({A}, {B, C}), ({B}, {A, C}), and ({C}, {A, B}). The algorithm evaluates the impurity of the resulting subsets for each possible binary split and chooses the one that maximizes information gain (or minimizes impurity).\n",
        "    *   **Multi-way Splits (less common)**: Some older decision tree algorithms (like ID3) can create multi-way splits, where a single node splits into multiple branches, one for each unique value of the categorical feature. However, this can lead to very bushy trees that are prone to overfitting, and binary splits are generally preferred in modern implementations (like CART and C4.5)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78595b4a"
      },
      "source": [
        "Ques -15. What are some real-world applications of Decision Trees?\n",
        "\n",
        "--> Decision Trees are a versatile machine learning algorithm with applications in a wide range of real-world scenarios due to their interpretability, ability to handle different data types, and effectiveness in both classification and regression tasks. Here are some common applications:\n",
        "\n",
        "1.  **Medical Diagnosis**: Decision trees are used to build models that can help diagnose diseases based on patient symptoms, medical history, and test results. The tree structure can provide insights into which factors are most important for diagnosis.\n",
        "2.  **Credit Risk Assessment**: Banks and financial institutions use decision trees to assess the creditworthiness of loan applicants. Based on factors like income, credit history, and debt-to-income ratio, a decision tree can predict the likelihood of a loan default.\n",
        "3.  **Customer Relationship Management (CRM)**: Decision trees are used in CRM to analyze customer data and predict customer behavior, such as churn (likelihood of a customer leaving), purchase intent, and customer segmentation. This helps businesses tailor marketing strategies and improve customer retention.\n",
        "4.  **Fraud Detection**: Decision trees can be used to identify fraudulent transactions in various domains, including credit card fraud, insurance fraud, and online fraud. By analyzing transaction patterns and characteristics, the tree can flag suspicious activities.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical"
      ],
      "metadata": {
        "id": "_yzGAI0_WAk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ques -1. Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy.\n",
        "# ðŸŒ¸ Decision Tree Classifier on the Iris Dataset\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Labels\n",
        "\n",
        "#  Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Decision Tree Classifier Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVpj1Uw8WRYJ",
        "outputId": "1c49f5fa-f8f9-4526-f62d-8d45b71f4d1a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ques -2. Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the feature importances\n",
        "# Decision Tree with Gini Impurity & Feature Importances\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree using Gini Impurity\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importances\n",
        "importances = clf.feature_importances_\n",
        "print(\"Feature Importances (Gini-based):\")\n",
        "for name, importance in zip(feature_names, importances):\n",
        "    print(f\"{name}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSaPtdrmXGxq",
        "outputId": "028fc406-f068-4d70-c5ea-99b659fe0ab2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances (Gini-based):\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0167\n",
            "petal length (cm): 0.9061\n",
            "petal width (cm): 0.0772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ques -3. Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the model accuracy.\n",
        "# Decision Tree Classifier using Entropy on the Iris Dataset\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree using Entropy\n",
        "clf = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Decision Tree Classifier Accuracy (Entropy): {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-DjriSIXs4q",
        "outputId": "7da4d37d-6c78-48fb-e0f5-14afa14ed14e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier Accuracy (Entropy): 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ques -4. Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean Squared Error (MSE).\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# Load the data\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "# Splits the datasets into training and testing the datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Train the decision tree regressor\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "# Make predictions on the test set\n",
        "y_pred = regressor.predict(X_test)\n",
        "# Evaluate using mean squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFl1f60AYN-p",
        "outputId": "6956b102-b11d-4da3-a65e-6b56df3ecbf6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ques -5. Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "import pydotplus\n",
        "from IPython.display import Image\n",
        "from graphviz import Source\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "# Split the datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X, y)\n",
        "# Export tree to dot format\n",
        "dot_data = export_graphviz(clf, out_file=None,\n",
        "                           feature_names=iris.feature_names,\n",
        "                           class_names=iris.target_names,\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "# Create a graph from a dot data\n",
        "graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "# Display the tree as an image\n",
        "graph.write_png('iris_tree.png')\n",
        "Image(graph.create_png())\n",
        "print(\"Decision Tree saved as 'iris_tree.png'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UBS7JDpbhsa",
        "outputId": "00b6c7d5-fdbf-447e-a589-e3cb26a3e95c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree saved as 'iris_tree.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques -6. Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its accuracy with a fully grown tree.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# train a decision tree classifier\n",
        "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with a maximum depth of 3: {accuracy:.2f}\")\n",
        "# Compare accuracy with grown tree\n",
        "clf_full = DecisionTreeClassifier(random_state=42)\n",
        "clf_full.fit(X_train, y_train)\n",
        "y_pred_full = clf_full.predict(X_test)\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "print(f\"Accuracy with a fully grown tree: {accuracy_full:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm2vP392eTjB",
        "outputId": "c12cc381-9ad9-477c-b132-74d0333aff4c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with a maximum depth of 3: 1.00\n",
            "Accuracy with a fully grown tree: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques -7. Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its accuracy with a default tree.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Train a decision tree classifier\n",
        "clf = DecisionTreeClassifier(min_samples_split=5, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with min_samples_split=5: {accuracy:.2f}\")\n",
        "# Compare accuracy with default tree\n",
        "clf_default = DecisionTreeClassifier(random_state=42)\n",
        "clf_default.fit(X_train, y_train)\n",
        "y_pred_default = clf_default.predict(X_test)\n",
        "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
        "print(f\"Accuracy with default tree: {accuracy_default:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqzWZN5LfrK0",
        "outputId": "254cf330-ea78-4975-e73e-c9200fa88b59"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with min_samples_split=5: 1.00\n",
            "Accuracy with default tree: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ques -8. Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its accuracy with unscaled data.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#load iris data\n",
        "iris=load_iris()\n",
        "x=iris.data\n",
        "y=iris.target\n",
        "# Split into training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "# train on unscaled data\n",
        "clf_unscaled = DecisionTreeClassifier()\n",
        "clf_unscaled.fit(X_train, y_train)\n",
        "y_pred_unscaled = clf_unscaled.predict(X_test)\n",
        "accuracy_unscaled = accuracy_score(y_test, y_pred_unscaled)\n",
        "print(\"Accuracy with unscaled data:\", accuracy_unscaled)\n",
        "# Apply feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# train on scaled data\n",
        "clf_scaled = DecisionTreeClassifier()\n",
        "clf_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = clf_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score\n",
        "print(\"Accuracy with scaled data:\", accuracy_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGxpFQ6DgqrV",
        "outputId": "29fe7387-2d59-4ed1-f568-ebf5177cc40d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with unscaled data: 1.0\n",
            "Accuracy with scaled data: <function accuracy_score at 0x7b6c587d0900>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques -9. Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass classification.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "# Split into traning and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Create a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "# Train the classifier using One-vs-Rest strategy\n",
        "ovr_clf = OneVsRestClassifier(clf)\n",
        "ovr_clf.fit(X_train, y_train)\n",
        "# Predict and evaluate\n",
        "y_pred = ovr_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with One-vs-Rest Strategy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYZ2PXDbiNc_",
        "outputId": "8f6a6a16-374b-439d-dc03-058fce602736"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with One-vs-Rest Strategy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques -10. Write a Python program to train a Decision Tree Classifier and display the feature importance scores\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "# Split into training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Train the classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "# Display feature importance scores\n",
        "feature_importances = clf.feature_importances_\n",
        "for feature_name, importance in zip(iris.feature_names, feature_importances):\n",
        "    print(f\"{feature_name}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7qGW4J0qJcS",
        "outputId": "474ab6f8-18d6-491e-bea5-6c8fb9876bf4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0167\n",
            "petal length (cm): 0.9061\n",
            "petal width (cm): 0.0772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques -11. Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance with an unrestricted tree.\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a pruned Decision Tree Regressor (max_depth=5)\n",
        "regressor_pruned = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
        "regressor_pruned.fit(X_train, y_train)\n",
        "y_pred_pruned = regressor_pruned.predict(X_test)\n",
        "mse_pruned = mean_squared_error(y_test, y_pred_pruned)\n",
        "\n",
        "# Train a fully grown Decision Tree Regressor (no depth limit)\n",
        "regressor_full = DecisionTreeRegressor(random_state=42)\n",
        "regressor_full.fit(X_train, y_train)\n",
        "y_pred_full = regressor_full.predict(X_test)\n",
        "mse_full = mean_squared_error(y_test, y_pred_full)\n",
        "\n",
        "# Compare results\n",
        "print(f\"Pruned Tree (max_depth=5) MSE: {mse_pruned:.4f}\")\n",
        "print(f\"Fully Grown Tree MSE:         {mse_full:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNsUrvRBrCbB",
        "outputId": "dfa6d9b3-a899-4ddc-830f-566abcea7909"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruned Tree (max_depth=5) MSE: 0.5245\n",
            "Fully Grown Tree MSE:         0.4952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques -12.  Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and visualize its effect on accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "import pydotplus\n",
        "from IPython.display import Image\n",
        "from graphviz import Source\n",
        "from sklearn.tree import _tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "# Split into traing and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "# Apply CCP\n",
        "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
        "# Train Decision Tree using CCP\n",
        "clfs = []\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
        "    clf.fit(X_train, y_train)\n",
        "    clfs.append(clf)\n",
        "    print(f\"Accuracy for alpha {ccp_alpha}: {clf.score(X_test, y_test):.4f}\")\n",
        "# Evaluate accuracy for each pruned tree\n",
        "train_scores = [clf.score(X_train, y_train) for clf in clfs]\n",
        "test_scores = [clf.score(X_test, y_test) for clf in clfs]\n",
        "# Plot the effect of pruning on accuracy\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_xlabel(\"Alpha\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "ax.set_title(\"Accuracy vs Alpha for Training and Testing Sets\")\n",
        "ax.plot(ccp_alphas, train_scores, marker='o', label=\"Train\", drawstyle=\"steps-post\")\n",
        "ax.plot(ccp_alphas, test_scores, marker='o', label=\"Test\", drawstyle=\"steps-post\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "JroKLKQXsoIx",
        "outputId": "8e2b6633-2686-4379-8ecd-456bbf61381f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for alpha 0.0: 1.0000\n",
            "Accuracy for alpha 0.008095238095238095: 1.0000\n",
            "Accuracy for alpha 0.01111111111111111: 1.0000\n",
            "Accuracy for alpha 0.011111111111111113: 1.0000\n",
            "Accuracy for alpha 0.01621621621621623: 1.0000\n",
            "Accuracy for alpha 0.024119601328903645: 0.9667\n",
            "Accuracy for alpha 0.24326537293107053: 0.6333\n",
            "Accuracy for alpha 0.3334027777777779: 0.3000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques -13. Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision, Recall, and F1-Score.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "# load iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "#Split into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Train decision tree classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QjRT4OCu74I",
        "outputId": "30660804-bcd3-45af-a53b-ae65850169cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques -14. Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize using seaborn\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "7QbxJCEtyQDi",
        "outputId": "9c0a3876-0696-496a-fab0-7509f56f588f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques -15. Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values for max_depth and min_samples_split.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "# Split into training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "#Define the parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5],\n",
        "    'min_samples_split': [2, 3, 4]\n",
        "}\n",
        "# Initialize the decision tree classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
        "# Fit the grid search to the data\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "# Best parameter and model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "# Evaluate the best model\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Accuracy with Best Model:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNF9Nro0zYmY",
        "outputId": "969c2fcb-9935-44a3-cf01-ef58f87e459c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 2}\n",
            "Accuracy with Best Model: 1.0\n"
          ]
        }
      ]
    }
  ]
}